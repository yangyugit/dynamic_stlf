%% bagging cnn ensemble method%% ihepc dataset ----------------------------------------------------------clear allload ..\ihepc_dataset.mat%% divide the training, validation, and testing datasetstart_index = 37+360 + 15*24*60;  % time(start_index) is 01-Jan-2007 00:00:00end_index = start_index + (31+28)*24*60; tr_index = [start_index : end_index]; va_index = [end_index: end_index + 7*24*60];te_index = [end_index + 7*24*60 : end_index + 7*24*60+7*24*60];time = time(1: te_index(end)+1); active_power = active_power(1:te_index(end)+1);% record the true value of testing datatrue_value = active_power(te_index)';% add the measurement noise[nor_data, min_data, gap_data] = minmaxnor(active_power);measure_noise_var = 0.025;measure_noise = normrnd(0, measure_noise_var, [1, size(active_power, 1)])';nor_data = nor_data + measure_noise;active_power = versenor(nor_data, min_data, gap_data);load ..\test_case_1\case1_ihepc_bagging_cnn_model.mat% testing data_set[te_dataset(te_index(1)-200: te_index(end)), te_min, te_gap] ...        = minmaxnor(active_power(te_index(1)-200:te_index(end), :));te_dataset = te_dataset';k = 1;for i = te_index(1): te_index(end)    te_x{k} = te_dataset(i-(200): i-1, :)';    te_y{k} = te_dataset(i, 1)';    k = k+1;end% construct the 4-D doubule for i = 1: size(te_x, 2)    te_X(:, :, 1, i) = te_x{i};    te_Y(i,:) = te_y{i}; endfor j = 1:5    for i = 1: size(te_x, 2)        YPre(j,i) = predict(cnn_net{j},te_X(:, :, 1, i), 'ExecutionEnvironment','gpu');    endendYpre1 = mean(YPre, 1); % the bagging forecasting% min max reversebagging_cnn_pre = versenor(Ypre1, te_min, te_gap);save('case2_ihepc_bagging_cnn_forecast.mat', 'bagging_cnn_pre')% rmsermse_ihepc_bagging_cnn = rmse_1(true_value, bagging_cnn_pre)figure()plot(time(te_index), bagging_cnn_pre, 'b')hold onplot(time(te_index), true_value, 'r')title('The performance of cnn')legend('forecast', 'true')%% aep dataset ------------------------------------------------------------clear allload ..\aep_dataset.mat%% divide the training, validation, and testing datasetstart_index = 1+144*4*30+41 - 144*(30+30+30+30); te_index = [(1+144*4*30 + 41) : (1+144*4*30 + 41) + 7*144]; % one week to testva_index = te_index - 7*144; % the previous week to validatetr_index = [start_index : va_index(1)]; % record the true testing datasettrue_value = series_data(te_index, 1)';% add the measurement noise[nor_data, min_data, gap_data] = minmaxnor(series_data(:, 1));measure_noise_var = 0.025; measure_noise = normrnd(0, measure_noise_var, [1, size(series_data, 1)])';nor_data = nor_data + measure_noise;series_data(:, 1) = versenor(nor_data, min_data, gap_data);load ..\test_case_1\case1_aep_bagging_cnn_model.mat% testing data_set[te_dataset(te_index(1)-200: te_index(end), 1), te1_min, te1_gap] ...            = minmaxnor(series_data(te_index(1)-200: te_index(end), 1));[te_dataset(te_index(1)-200: te_index(end), 2), te2_min, te2_gap] ...            = minmaxnor(series_data(te_index(1)-200: te_index(end), 2));k = 1;for i = te_index(1): te_index(end)    te_x{k} = te_dataset(i-(200): i-1, :)';    te_y{k} = te_dataset(i, 1)';    k = k+1;end% construct the 4-D doubule for i = 1: size(te_x, 2)    te_X(:, :, 1, i) = te_x{i};    te_Y(i,:) = te_y{i}; end% see the testing effectfor j = 1:5    for i = 1: size(te_x, 2)        YPre(j,i) = predict(cnn_net{j}, te_X(:, :, 1, i), 'ExecutionEnvironment','gpu');    endendYpre1 = mean(YPre, 1); % the bagging forecasting% min max reversebagging_cnn_pre = versenor(Ypre1, te1_min, te1_gap);save('case2_aep_bagging_cnn_forecast.mat', 'bagging_cnn_pre')% rmsermse_aep_bagging_cnn = rmse_1(true_value, bagging_cnn_pre)figure()plot(time(te_index), bagging_cnn_pre, 'b')hold onplot(time(te_index), true_value, 'r')title('The performance of cnn')legend('forecast', 'true')